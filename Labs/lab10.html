<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="../styles.css" />
    <title>Lab 10</title>
  </head>
  <body>
    <header>
      <h1>Fast Robots - Austin Townsend</h1>
      <nav>
        <ul>
          <li><a href="https://austintownsend.github.io/Fast-Robots-Austin/index.html">Home</a></li>
          <li><a href="lab1A.html">Lab 1A</a></li>
          <li><a href="lab1B.html">Lab 1B</a></li>
          <li><a href="lab2.html">Lab 2</a></li>
          <li><a href="lab3.html">Lab 3</a></li>
          <li><a href="lab4.html">Lab 4</a></li>
          <li><a href="lab5.html">Lab 5</a></li>
          <li><a href="lab6.html">Lab 6</a></li>
          <li><a href="lab7.html">Lab 7</a></li>
          <li><a href="lab8.html">Lab 8</a></li>
          <li><a href="lab9.html">Lab 9</a></li>
          <li><a href="lab10.html">Lab 10</a></li>
        </ul>
      </nav>
    </header>

    <section class="content">
      <h2>Lab 10</h2>

      <p>
        The purpose of this lab is to implement grid localization using Bayes filter.
      </p>

      <h3>Bayes Basics</h3>

      <p>
        The Bayes filter uses a combination of a control input, measurements from
        sensors, and then establishes a belief of where the robot currently is.
        After every input (tell the robot to move somewhere), there is a probability
        that the robot is actually at the location and also a non-zero probability
        that the robot is at a different state. The Bayes filter tries to converge
        on the actual position by making a prediction and then continuosly updating
        based on the previous position. The basic algorithm for the Bayes filter
        is shown below.
      </p>

      <img src="BAYES ALGO.png" alt="bayes algorithm" width="700" />

      <h3>Compute Control</h3>

      <p>
        The computation consists of three parts: the first is a rotation in the
        direction of the new location, then a linear translation to the new location,
        then finally a second rotation to correct the robot's orientation. The
        calculation is shown below.
      </p>

      <img src="BAYES COMPUTE.png" alt="bayes compute" width="700" />

      <h3>Odomoetry Motion Model</h3>

      <p>
        This code uses a gaussian distribution to determine the probability that
        the robot actually moved based on the input control. This process is repeated
        for each movement described above, and then the probabilities are multiplied
        together to get an overall probability. The code is shown below.
      </p>

      <img src="BAYES ODOM.png" alt="bayes odom" width="700" />

      <h3>Prediction Step</h3>

      <p>
        The prediction code predicts the probability that the robot will be at some
        state given its belief it was at the previous state and underwent the given
        control input. Rather then setting a belief of 0 to 0, I used a value of
        0.0001 in order to prevent issues with the probabilities. The code is shown
        below.
      </p>

      <img src="BAYES PREDICT.png" alt="bayes predict" width="700" />

      <h3>Sensor Model</h3>

      <p>
        This function runs through 18 different measurements to determine the
        probability of a sensor measurement given the current position. Overall,
        this code defines the probability that is used in other functions. The code
        is shown below.
      </p>

      <img src="BAYES SENSOR.png" alt="bayes sensor" width="700" />

      <h3>Update Step</h3>

      <p>
        This function takes the predicted belief (bel_bar), and it updates the
        belief based on the sensor input value. This is done by multiplying the
        probability from the measurement and the predicted belief state. Then, the
        value is normalized to keep the sum of the probabilities equal to one. The
        code is shown below,
      </p>

      <img src="BAYES UPDATE.png" alt="bayes update" width="700" />

      <h3>Simulation Results</h3>

      <p>
        The simulation results are shown below. The odomoetry model (shown in red)
        is very inaccurate. However, the true results (shown in green) and the
        belief results (shown in blue) are pretty close. This means that the
        prediction from the Bayes filter is pretty good and converges nicely. While
        the filter did stray a little at a few of the points, it was able to get
        itself back on track quickly.
      </p>

      <iframe width="1120" height="630" src="https://www.youtube.com/embed/YlDUBAB7S9k?si=uZ_3_6ak7b0FkG8E"
      title="YouTube video player" frameborder="0" allow="accelerometer; autoplay;
      clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
      referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
      <img src="SIM MAP.png" alt="sim map" width="500" />
      <img src="BAYES MAP.png" alt="bayes map" width="600" />

      <h3>Lab 10 Takeaways</h3>

      <p>

      </p>

    </section>
  </body>
</html>
